Search.setIndex({"docnames": ["CONCEPTS/parallel_context", "CONCEPTS/tensor_model_parallelism", "CONCEPTS/tp/1d_parallel_algorithm", "CONCEPTS/tp/2d_parallel_algorithm", "CONCEPTS/tp/2p5d_parallel_algorithm", "CONCEPTS/tp/3d_parallel_algorithm", "TUTORIALS/tensor_model_parallelism", "index"], "filenames": ["CONCEPTS/parallel_context.md", "CONCEPTS/tensor_model_parallelism.md", "CONCEPTS/tp/1d_parallel_algorithm.md", "CONCEPTS/tp/2d_parallel_algorithm.md", "CONCEPTS/tp/2p5d_parallel_algorithm.md", "CONCEPTS/tp/3d_parallel_algorithm.md", "TUTORIALS/tensor_model_parallelism.md", "index.rst"], "titles": ["Concept of Parallel Context", "Concept of Tensor Model Parallelism", "1D parallel algorithm (same as Megatron-LM)", "2D parallel (SUMMA) algorithm", "2.5D parallel (SUMMA-2.5) algorithm", "3D parallel Algorithm", "Tensor Model Parallelism Tutorial", "OSLO: Open Source for Large-scale Optimization"], "terms": {"i": [0, 2, 3, 4, 5, 6], "distribut": [0, 1, 2, 3], "process": 0, "group": 0, "manag": [0, 7], "oslo": [0, 2, 3, 4, 5, 6], "you": [0, 6, 7], "can": [0, 2, 3, 4, 6, 7], "put": 0, "desir": 0, "class": 0, "There": [0, 6], "ar": [0, 3, 6, 7], "three": [0, 5, 6], "method": [0, 1, 6], "If": [0, 6, 7], "us": [0, 1, 2, 3, 4, 5, 6, 7], "pytorch": [0, 6], "launcher": 0, "function": [0, 6], "from": [0, 2, 3, 4, 5, 6], "torch": [0, 2, 3, 4, 5, 6], "import": [0, 2, 3, 4, 5, 6], "parallelcontext": [0, 2, 3, 4, 5, 6], "parallel_context": [0, 2, 3, 4, 5, 6], "data_parallel_s": [0, 2, 3, 4, 5, 6], "tensor_parallel_s": [0, 2, 3, 4, 5, 6], "pipeline_parallel_s": [0, 2, 3, 4, 5, 6], "sequence_parallel_s": 0, "expert_parallel_s": 0, "slurm": [0, 6], "In": [0, 6], "thi": [0, 3, 4, 5, 6], "case": 0, "must": [0, 6], "input": [0, 3, 4, 5], "host": 0, "port": [0, 6], "togeth": 0, "your_host": 0, "your_port": 0, "openmpi": 0, "similar": [0, 6], "an": [0, 1, 2, 6], "enum": 0, "name": [0, 6, 7], "parallelmod": [0, 2, 3, 4, 5, 6], "global_rank": 0, "get_local_rank": 0, "global": 0, "data_parallel_rank": 0, "data": [0, 6], "tensor_parallel_rank": 0, "tensor": [0, 2, 3, 4, 5, 7], "pipeline_parallel_rank": 0, "pipelin": 0, "sequence_parallel_rank": 0, "sequenc": [0, 6], "expoert_parallel_rank": 0, "expert": 0, "global_s": 0, "get_world_s": 0, "expoert_parallel_s": 0, "author": [1, 2, 3, 4, 5, 6, 7], "kichang": [1, 2, 3, 4, 5, 6], "yang": [1, 2, 3, 4, 5, 6], "kevin": [1, 2, 3, 4, 5, 6], "ko": [1, 2, 3, 4, 5, 6], "make": [1, 6, 7], "possibl": [1, 6], "train": [1, 2, 7], "larger": [1, 6], "partit": [1, 2, 3, 6], "paramet": [1, 2, 3, 4, 5, 6], "multipl": [1, 2, 4, 5, 6], "dimens": [1, 2, 5, 6], "we": [1, 6, 7], "support": [1, 6], "1d": [1, 3, 4, 5], "2d": [1, 4, 5, 6], "2": [1, 2, 5, 7], "5d": [1, 5, 6], "3d": [1, 6, 7], "which": [1, 4, 5, 6, 7], "more": [1, 3, 4, 5, 6, 7], "effici": [1, 3, 6], "same": [1, 6], "megatron": [1, 6], "lm": [1, 6], "summa": [1, 5, 6], "5": 1, "multi": 1, "billion": [1, 2], "languag": [1, 2], "super": 1, "larg": [1, 2, 3, 5], "deep": 1, "learn": 1, "dimension": 1, "maxim": 1, "huge": 1, "neural": [1, 5], "network": [1, 5], "minho": [2, 3, 4, 5], "ryu": [2, 3, 4, 5], "paper": [2, 3, 4, 5], "http": [2, 3, 4, 5, 7], "arxiv": [2, 3, 4, 5], "org": [2, 3, 4, 5], "pdf": [2, 3, 4, 5], "1909": 2, "08053": 2, "techniqu": [2, 5], "model": [2, 3, 4, 5, 7], "weight": [2, 3, 4, 5], "across": 2, "devic": [2, 4, 5, 7], "reduc": [2, 4, 5], "memori": [2, 3, 4, 5], "load": [2, 3], "split": [2, 3, 4, 5, 6], "each": [2, 4, 6], "layer": [2, 3, 4, 5, 6], "smaller": [2, 4, 6], "chunk": 2, "along": [2, 3, 5], "one": [2, 5, 6], "them": 2, "among": [2, 5], "differ": [2, 6], "For": [2, 3, 6], "exampl": [2, 6], "linear": [2, 3, 4], "y": [2, 3], "xa": [2, 3], "column": [2, 3, 5, 6], "row": [2, 3, 5, 6], "fashion": 2, "A": [2, 3, 5], "a1": 2, "a2": 2, "comput": [2, 3, 4, 5], "y_i": 2, "xa_i": 2, "b": 2, "b1": 2, "b2": 2, "z": 2, "y1": 2, "y2": 2, "all": [2, 7], "oper": [2, 4], "scale": [2, 3], "gpu": [2, 5, 6, 7], "cluster": [2, 5], "tensor_1d": [2, 6], "tensor_parallel_mod": [2, 3, 4, 5, 6], "should": [2, 3, 4, 5, 6], "divis": 2, "tp_size": [2, 3, 4, 5, 6], "defin": [2, 4, 5, 6], "section": [2, 4, 5, 6], "nn": [2, 3, 4, 5, 6], "tensorparallel": [2, 3, 4, 5, 6], "4": [2, 3], "tp_depth": [2, 3, 4, 5, 6], "1": [2, 3, 4, 5, 7], "from_torch": [2, 3, 4, 5, 6], "readi": [2, 3, 4, 5, 6], "2104": 3, "05343": 3, "The": [3, 4, 7], "lead": 3, "high": 3, "consumpt": 3, "becaus": [3, 6], "doe": 3, "activ": 3, "To": [3, 4], "address": [3, 4, 5], "issu": 3, "base": [3, 4, 5, 7], "wa": [3, 4], "introduc": [3, 5], "evenli": 3, "instanc": 3, "when": [3, 7], "x": [3, 6], "four": 3, "sub": [3, 4, 5], "matric": [3, 4], "calcul": 3, "done": 3, "two": 3, "step": [3, 6], "broadcast": 3, "turn": 3, "result": [3, 4], "matrix": [3, 4], "product": 3, "tensor_2d": [3, 6], "sinc": 3, "both": [3, 5], "squar": 3, "posit": [3, 5, 6], "integ": [3, 5], "2105": [4, 5], "14500": 4, "ha": [4, 5], "lower": [4, 6], "cost": [4, 5, 6], "than": [4, 6], "increas": 4, "commun": [4, 5, 6], "propos": [4, 5], "involv": [4, 5], "appli": 4, "output": 4, "combin": 4, "approach": 4, "other": 4, "tensor_2p5d": [4, 6], "It": 4, "recommend": [4, 6], "set": 4, "becom": 4, "ident": 4, "8": [4, 5, 6], "tensor_parallel_depth": [4, 6], "14450": 5, "have": [5, 6], "been": 5, "previous": 5, "challeng": 5, "pose": 5, "while": 5, "also": [5, 6], "final": 5, "further": 5, "har": 5, "capabl": 5, "divid": 5, "singl": [5, 6], "design": 5, "limit": 5, "tensor_3d": [5, 6], "cubic": [5, 6], "unlik": 6, "simpli": 6, "launch": 6, "torchrun": 6, "nproc_per_nod": 6, "your_script": 6, "py": 6, "instal": 6, "your": 6, "environ": 6, "follow": 6, "work": [6, 7], "srun": 6, "num_gpu": 6, "inform": 6, "refer": 6, "document": 6, "deepspe": 6, "how": 6, "warn": 6, "assign": 6, "cpu": 6, "cuda": 6, "transform": [6, 7], "automodelforcausallm": 6, "autotoken": 6, "from_pretrain": 6, "gpt2": 6, "onli": 6, "requir": 6, "just": 6, "call": 6, "here": 6, "explain": 6, "about": 6, "argument": 6, "total": 6, "num": 6, "power": 6, "e": 6, "g": 6, "16": 6, "number": 6, "type": 6, "detail": 6, "see": 6, "megatronlm": 6, "much": 6, "effect": 6, "between": 6, "mode": 6, "2p5d": 6, "Not": 6, "want": 6, "tensor_parallel": 6, "mix": 6, "pp": 6, "later": 6, "version": 6, "find": [6, 7], "concept": 6, "text": 6, "gener": 6, "addit": 6, "variou": [6, 7], "task": 6, "classif": 6, "mask": 6, "likewis": 6, "write": 6, "code": [6, 7], "don": 6, "t": 6, "lot": 6, "christma": 6, "thing": 6, "return_tensor": 6, "pt": 6, "print": 6, "decod": 6, "num_beam": 6, "batch_siz": 6, "seq_len": 6, "64": 6, "save_interv": 6, "50": 6, "train_step": 6, "100": 6, "adam": 6, "lr": 6, "3e": 6, "add": 6, "pad": 6, "batch": 6, "doesn": 6, "pad_token": 6, "eos_token": 6, "re": 6, "go": 6, "librari": 6, "hug": [6, 7], "face": [6, 7], "load_dataset": 6, "util": 6, "squad": 6, "context": [6, 7], "str": 6, "_": 6, "shuffl": 6, "true": 6, "enumer": 6, "zero_grad": 6, "input_batch": 6, "truncat": 6, "max_length": 6, "forward": [6, 7], "backward": 6, "loss": 6, "label": 6, "input_id": 6, "save_pretrain": 6, "so": 6, "Then": 6, "like": [6, 7], "pytorch_model_tp_": 6, "tp_rank": 6, "_pp_": 6, "pp_rank": 6, "_ep_": 6, "ep_rank": 6, "bin": 6, "local": 6, "path": 6, "save_directori": 6, "parallel_ckpt": 6, "statu": 6, "pass": 6, "merge_checkpoint": 6, "modifi": 6, "point": 6, "nnode": 6, "node_rank": 6, "master_addr": 6, "your_node_address": 6, "master_port": 6, "sbatch": 6, "file": 6, "run": 6, "sbatch_fil": 6, "sh": 6, "command": 6, "bash": 6, "job": 6, "jobnam": 6, "time": 6, "infinit": 6, "request": 6, "world_siz": 6, "note": 6, "gre": 6, "equal": 6, "ntask": 6, "per": 6, "mem": 6, "64gb": 6, "export": 6, "hostnam": 6, "scontrol": 6, "show": 6, "slurm_job_nodelist": 6, "head": 6, "n": 6, "count_nod": 6, "wc": 6, "l": 6, "python": 6, "And": 6, "framework": 7, "provid": 7, "technologi": 7, "featur": 7, "parallel": 7, "kernel": 7, "fusion": 7, "could": 7, "kei": 7, "easi": 7, "magic": 7, "compat": 7, "being": 7, "consid": 7, "de": 7, "facto": 7, "standard": 7, "nlp": 7, "field": 7, "look": 7, "democrat": 7, "significantli": 7, "decreas": 7, "difficulti": 7, "easili": 7, "pip": 7, "packag": 7, "Be": 7, "care": 7, "core": 7, "pypi": 7, "project": 7, "creat": 7, "object": 7, "check": 7, "rank": 7, "world": 7, "size": 7, "algorithm": 7, "our": 7, "pleas": 7, "misc": 7, "titl": 7, "howpublish": 7, "url": 7, "github": 7, "com": 7, "eleutherai": 7, "year": 7, "2021": 7, "under": 7, "term": 7, "apach": 7, "0": 7, "copyright": 7, "2022": 7, "right": 7, "reserv": 7}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"concept": [0, 1, 7], "parallel": [0, 1, 2, 3, 4, 5, 6], "context": 0, "1": [0, 6], "creat": [0, 6], "object": 0, "from_torch": 0, "2": [0, 4, 6], "from_slurm": 0, "3": [0, 6], "from_openmpi": 0, "check": 0, "devic": 0, "rank": 0, "world": 0, "size": 0, "easili": 0, "tensor": [1, 6], "model": [1, 6], "algorithm": [1, 2, 3, 4, 5, 6], "refer": 1, "1d": 2, "same": 2, "megatron": 2, "lm": 2, "usag": [2, 3, 4, 5], "2d": 3, "summa": [3, 4], "5d": 4, "5": [4, 6], "3d": 5, "tutori": [6, 7], "tabl": 6, "content": 6, "0": 6, "distribut": 6, "launcher": 6, "infer": 6, "token": 6, "do": 6, "usual": 6, "train": 6, "initi": 6, "some": 6, "variabl": 6, "optim": [6, 7], "4": 6, "load": 6, "dataset": 6, "dataload": 6, "6": 6, "save": 6, "merg": 6, "checkpoint": 6, "appendix": 6, "multi": 6, "node": 6, "oslo": 7, "open": 7, "sourc": 7, "larg": 7, "scale": 7, "what": 7, "i": 7, "about": 7, "instal": 7, "document": 7, "administr": 7, "note": 7, "cite": 7, "licens": 7}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Concept of Parallel Context": [[0, "concept-of-parallel-context"]], "1. Create Parallel Context object": [[0, "create-parallel-context-object"]], "1.1. from_torch": [[0, "from-torch"]], "1.2. from_slurm": [[0, "from-slurm"]], "1.3. from_openmpi": [[0, "from-openmpi"]], "2. Check device ranks and world sizes easily": [[0, "check-device-ranks-and-world-sizes-easily"]], "2.1. Ranks": [[0, "ranks"]], "2.2. World sizes": [[0, "world-sizes"]], "Concept of Tensor Model Parallelism": [[1, "concept-of-tensor-model-parallelism"]], "Tensor Parallel Algorithms": [[1, "tensor-parallel-algorithms"]], "References": [[1, "references"]], "1D parallel algorithm (same as Megatron-LM)": [[2, "d-parallel-algorithm-same-as-megatron-lm"]], "Usage": [[2, "usage"], [3, "usage"], [4, "usage"], [5, "usage"]], "2D parallel (SUMMA) algorithm": [[3, "d-parallel-summa-algorithm"]], "2.5D parallel (SUMMA-2.5) algorithm": [[4, "d-parallel-summa-2-5-algorithm"]], "3D parallel Algorithm": [[5, "d-parallel-algorithm"]], "Tensor Model Parallelism Tutorial": [[6, "tensor-model-parallelism-tutorial"]], "Table of contents": [[6, "table-of-contents"]], "0. Distributed Launcher": [[6, "distributed-launcher"]], "1. Inference": [[6, "inference"]], "1.1. Create model and tokenizer": [[6, "create-model-and-tokenizer"]], "1.2. Parallelize the model": [[6, "parallelize-the-model"]], "1.2.1 Tensor Parallel Algorithms": [[6, "tensor-parallel-algorithms"]], "1.3. Do inference as usual": [[6, "do-inference-as-usual"]], "2. Training": [[6, "training"]], "2.1. Initialize some variables": [[6, "initialize-some-variables"]], "2.2. Create model, optimizer and tokenizer": [[6, "create-model-optimizer-and-tokenizer"]], "2.3. Parallelize the model": [[6, "id1"]], "2.4. Load dataset and create dataloader": [[6, "load-dataset-and-create-dataloader"]], "2.5. Do training as usual": [[6, "do-training-as-usual"]], "2.6. Save the parallelized model": [[6, "save-the-parallelized-model"]], "2.6.1. Merging Checkpoints": [[6, "merging-checkpoints"]], "Appendix. Multi-node Training": [[6, "appendix-multi-node-training"]], "OSLO: Open Source for Large-scale Optimization": [[7, "oslo-open-source-for-large-scale-optimization"]], "What is OSLO about?": [[7, "what-is-oslo-about"]], "Installation": [[7, "installation"]], "Documents": [[7, "documents"]], "CONCEPTS": [[7, null]], "TUTORIALS": [[7, null]], "Administrative Notes": [[7, "administrative-notes"]], "Citing OSLO": [[7, "citing-oslo"]], "Licensing": [[7, "licensing"]]}, "indexentries": {}})